{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### Intro\\n\",\n",
    "    \"\\n\",\n",
    "    \"This notebook explores the model we made to determine Titanic survival/death probability based on a number of variables.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Libraries\\n\",\n",
    "    \"\\n\",\n",
    "    \"The libraries are used for various tasks such as web development (Flask), data manipulation (pandas), visualization (seaborn), machine learning (scikit-learn), and numerical computations (numpy).\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"from flask import Flask, request, jsonify, Blueprint\\n\",\n",
    "    \"from flask_restful import Api, Resource\\n\",\n",
    "    \"import seaborn as sns\\n\",\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"from sklearn.preprocessing import OneHotEncoder\\n\",\n",
    "    \"from sklearn.linear_model import LogisticRegression\\n\",\n",
    "    \"import numpy as np\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Blueprint/Resoucre Creation\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"titanic_api = Blueprint('titanic_api', __name__, url_prefix='/api/titanic')\\n\",\n",
    "    \"api = Api(titanic_api)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# TitanicAPI Class\\n\",\n",
    "    \"\\n\",\n",
    "    \"### Initialization\\n\",\n",
    "    \"\\n\",\n",
    "    \"--> Initialize machine learning model and prepare the Titanic dataset.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 2,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"ename\": \"NameError\",\n",
    "     \"evalue\": \"name 'Resource' is not defined\",\n",
    "     \"output_type\": \"error\",\n",
    "     \"traceback\": [\n",
    "      \"\\u001b[0;31m---------------------------------------------------------------------------\\u001b[0m\",\n",
    "      \"\\u001b[0;31mNameError\\u001b[0m                                 Traceback (most recent call last)\",\n",
    "      \"Cell \\u001b[0;32mIn[2], line 1\\u001b[0m\\n\\u001b[0;32m----> 1\\u001b[0m \\u001b[39mclass\\u001b[39;00m \\u001b[39mTitanicAPI\\u001b[39;00m(Resource):\\n\\u001b[1;32m      2\\u001b[0m     \\u001b[39mdef\\u001b[39;00m \\u001b[39m__init__\\u001b[39m(\\u001b[39mself\\u001b[39m):\\n\\u001b[1;32m      3\\u001b[0m         \\u001b[39m# Load the Titanic dataset\\u001b[39;00m\\n\\u001b[1;32m      4\\u001b[0m         titanic_data \\u001b[39m=\\u001b[39m sns\\u001b[39m.\\u001b[39mload_dataset(\\u001b[39m'\\u001b[39m\\u001b[39mtitanic\\u001b[39m\\u001b[39m'\\u001b[39m)\\n\",\n",
    "      \"\\u001b[0;31mNameError\\u001b[0m: name 'Resource' is not defined\"\n",
    "     ]\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"class TitanicAPI(Resource):\\n\",\n",
    "    \"    def __init__(self):\\n\",\n",
    "    \"        # Load the Titanic dataset\\n\",\n",
    "    \"        titanic_data = sns.load_dataset('titanic')\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        # Preprocess the dataset\\n\",\n",
    "    \"        td = titanic_data.copy()\\n\",\n",
    "    \"        td.drop(['alive', 'who', 'adult_male', 'class', 'embark_town', 'deck'], axis=1, inplace=True)\\n\",\n",
    "    \"        td.dropna(inplace=True)\\n\",\n",
    "    \"        td['sex'] = td['sex'].apply(lambda x: 1 if x == 'male' else 0)\\n\",\n",
    "    \"        td['alone'] = td['alone'].apply(lambda x: 1 if x else 0)\\n\",\n",
    "    \"\\n\",\n",
    "    \"        # Encode categorical variables\\n\",\n",
    "    \"        self.enc = OneHotEncoder(handle_unknown='ignore')\\n\",\n",
    "    \"        embarked_encoded = self.enc.fit_transform(td[['embarked']].values.reshape(-1, 1))\\n\",\n",
    "    \"        self.encoded_cols = self.enc.get_feature_names_out(['embarked'])\\n\",\n",
    "    \"        td[self.encoded_cols] = embarked_encoded.toarray()\\n\",\n",
    "    \"        td.drop(['embarked'], axis=1, inplace=True)\\n\",\n",
    "    \"\\n\",\n",
    "    \"        # Initialize Logistic Regression model\\n\",\n",
    "    \"        self.logreg = LogisticRegression(max_iter=1000)\\n\",\n",
    "    \"        X = td.drop('survived', axis=1)\\n\",\n",
    "    \"        y = td['survived']\\n\",\n",
    "    \"        self.logreg.fit(X, y)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### predict_survival Method\\n\",\n",
    "    \"\\n\",\n",
    "    \"Takes passenger data as input, preprocesses it --> uses the trained Logistic Regression model to predict survival probabilities.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"    def predict_survival(self, data):\\n\",\n",
    "    \"        try:\\n\",\n",
    "    \"            # Preprocess input data\\n\",\n",
    "    \"            passenger = pd.DataFrame([data]) \\n\",\n",
    "    \"            passenger['sex'] = passenger['sex'].apply(lambda x: 1 if x == 'male' else 0)\\n\",\n",
    "    \"            passenger['alone'] = passenger['alone'].apply(lambda x: 1 if x else 0)\\n\",\n",
    "    \"            embarked_encoded = self.enc.transform(passenger[['embarked']].values.reshape(-1, 1))\\n\",\n",
    "    \"            passenger[self.encoded_cols] = embarked_encoded.toarray()\\n\",\n",
    "    \"            passenger.drop(['embarked', 'name'], axis=1, inplace=True)\\n\",\n",
    "    \"\\n\",\n",
    "    \"            # Predict survival probabilities\\n\",\n",
    "    \"            dead_proba, alive_proba = np.squeeze(self.logreg.predict_proba(passenger))\\n\",\n",
    "    \"\\n\",\n",
    "    \"            return {\\n\",\n",
    "    \"                'Death probability': '{:.2%}'.format(dead_proba),\\n\",\n",
    "    \"                'Survival probability': '{:.2%}'.format(alive_proba)\\n\",\n",
    "    \"            }\\n\",\n",
    "    \"        except Exception as e:\\n\",\n",
    "    \"            return {'error': str(e)}\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### Endpoint\\n\",\n",
    "    \"\\n\",\n",
    "    \"- Define a POST endpoint /predict to receive passenger data --> return survival predictions.\\n\",\n",
    "    \"- Endpoint essentially also handles exceptions and returns appropriate responses.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 1,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"ename\": \"NameError\",\n",
    "     \"evalue\": \"name 'api' is not defined\",\n",
    "     \"output_type\": \"error\",\n",
    "     \"traceback\": [\n",
    "      \"\\u001b[0;31m---------------------------------------------------------------------------\\u001b[0m\",\n",
    "      \"\\u001b[0;31mNameError\\u001b[0m                                 Traceback (most recent call last)\",\n",
    "      \"Cell \\u001b[0;32mIn[1], line 9\\u001b[0m\\n\\u001b[1;32m      6\\u001b[0m     \\u001b[39mexcept\\u001b[39;00m \\u001b[39mException\\u001b[39;00m \\u001b[39mas\\u001b[39;00m e:\\n\\u001b[1;32m      7\\u001b[0m         \\u001b[39mreturn\\u001b[39;00m jsonify({\\u001b[39m'\\u001b[39m\\u001b[39merror\\u001b[39m\\u001b[39m'\\u001b[39m: \\u001b[39mstr\\u001b[39m(e)})\\n\\u001b[0;32m----> 9\\u001b[0m api\\u001b[39m.\\u001b[39madd_resource(TitanicAPI, \\u001b[39m'\\u001b[39m\\u001b[39m/predict\\u001b[39m\\u001b[39m'\\u001b[39m)\\n\",\n",
    "      \"\\u001b[0;31mNameError\\u001b[0m: name 'api' is not defined\"\n",
    "     ]\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"    def post(self):\\n\",\n",
    "    \"        try:\\n\",\n",
    "    \"            data = request.json\\n\",\n",
    "    \"            result = self.predict_survival(data)\\n\",\n",
    "    \"            return jsonify(result)\\n\",\n",
    "    \"        except Exception as e:\\n\",\n",
    "    \"            return jsonify({'error': str(e)})\\n\",\n",
    "    \"\\n\",\n",
    "    \"api.add_resource(TitanicAPI, '/predict')\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.11.7\"\n",
    "  },\n",
    "  \"orig_nbformat\": 4\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 2\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
